---
title: Ollama - 로컬 LLM 모델
permalink: 
tags: 
Keywords:
  - "[[AI(인공지능)]]"
aliases: 
description: 
updated: 
created: 2024-02-25
publish: true
---
free-tags:: #LLM/Local 

## 개요
- [Ollama](https://ollama.com/)는 Local [[Large Language Model|LLM]]이다.
	- Local -> 내 컴퓨터에 *직접 설치*해서 사용
	- Cloud -> 서버를 통해 사용
		- 예) ChatGPT, Gemini 등
- [WEB GUI](https://ollama-gui.vercel.app/)

## How to Use?
>토요일 오전에 맥에서 Ollama 설치 후 옵시디언 Ollama 커뮤니티 플러그인 설치해서 놀아보는데, 뭔가 로컬 AI의 미래를 엿보고 온 기분이내요.
> 
> 1. Local LLM, Ollama - https://ollama.com/ 를 로컬에 먼저 설치 - 맥과 윈도우(프리뷰 버전) 모두 있음. 맥버전이 우선은 더 안정적으로 돌아가는거 같습니다. 
> 
> 2. 옵시디언 커뮤니티 플러그인에서 Ollama로 검색을 해보시면 3개의 플러그인을 보실 수 있는데
> 
> 2-1. Ollama - 옵시디언에 Ollama를 활용 요약, 다시 쓰기, 설명하라고 하기 등이 가능, 프롬프트 튜닝을 통해 모델과 템퍼처 설정 가능. 가장 단순한 형태로 활용
> 
> 2-2. Ollama Chat - LlamaIndex로 노트들을 인덱스한 후 내 옵시디언 볼트의 노트들을 기반으로 Ollama와 대화할 수 있게 해주는 플러그인
> 
> 2-3. Smart Second Brain - Ollama와 GPT API를 지원 - 옵시디언의 이전 메모들을 활용한 무엇보다 새로운 노트 작성시 도움을 받는 등. 
> 
> —더배러 커뮤니티 카톡[[Hannah Arendt]]
